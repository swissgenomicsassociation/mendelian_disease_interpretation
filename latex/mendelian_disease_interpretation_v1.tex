\input{head.tex}

\begin{document}

\newcounter{myboxcounter}
\newcommand{\boxlabel}[1]{%
  \refstepcounter{myboxcounter}%
  \label{#1}%
}

\title{Swiss Genomics Association consensus guideline for evidence-based genomic variant interpretation in Mendelian disease}

% in your preamble, before \author:
\newcommand{\QUANT}{1}
\newcommand{\IPSNEO}{2}
\newcommand{\SGA}{3}
%\newcommand{\GHI}{2}
%\newcommand{\KISPIIMM}{3}
% \newcommand{\METAB}{4}
%\newcommand{\LEEDS}{5}

\author[\QUANT]{Quant Group} 
%\author[\GHI]{Simon Boutry}% \textsuperscript{†}}
%\author[\GHI]{Ali Saadat}% \textsuperscript{†}} \textsuperscript{†}}
%\author[\KISPIIMM]{Maarja Soomann}% \textsuperscript{†}} \textsuperscript{†}}
%\author[\KISPIIMM]{Johannes Trück}
%\author[\GHI]{Jacques Fellay}
\author[\IPSNEO]{Dylan Lawless *}
\author[\SGA]{the joint 
SGA committee}
% \textsuperscript{†}
\affil[\QUANT]{The quantitative omic epidemiology group.} 
\affil[\SGA]{The Swiss Genomics Association  commitee.}
%\affil[\GHI]{Global Health Institute, School of Life Sciences, École Polytechnique Fédérale de Lausanne, Switzerland.}
%\affil[\KISPIIMM]{Division of Immunology and the Children’s Research Center, University Children’s Hospital Zurich, University of Zurich, Zurich, Switzerland.}
%\affil[\LEEDS]{Leeds Institute of Rheumatic and Musculoskeletal Medicine, University of Leeds, Leeds, UK.}
\affil[\IPSNEO]{Department of Intensive Care and Neonatology, University Children's Hospital Zurich, University of Zurich, Zurich, Switzerland.}

\maketitle
% \justify
\raggedright

\begin{tcolorbox}[
  colback=red!5!white,
  colframe=red!60!black,
  title=\textcolor{white}{\textbf{DRAFT – NOT FINAL}},
  fonttitle=\large\bfseries,
  coltitle=white,
  left=2mm, right=2mm, top=1mm, bottom=1mm,
  boxrule=0.8pt,
  sharp corners,
  enhanced,
  title filled=true,
  colbacktitle=red!80!black
]
This document is a \textbf{live public working draft} and does not represent a completed or officially endorsed release.  
All statements, analyses, and opinions are those of the authors and have not yet undergone joint committee review or external peer review.  
Content is provided for transparency and collaborative development and may be revised substantially prior to publication.
\end{tcolorbox}
%\vspace{1em}
\clearpage

%  \linenumbers
\begin{abstract}
\noindent
% \vspace{1em}
Genomic medicine programmes across the world are advancing rapidly, especially with AI, but variant interpretation remains implemented differently across national, institutional and commercial efforts, with no shared agreement on how supporting evidence should be structured, recorded or exchanged. As a result, equivalent data are repeatedly recomputed, manually curated or privately remodelled, while shared learning, verification and reuse remain limited. Key evidence including inheritance, provenance, population context, functional data and conflicting observations is inconsistently captured, reducing transparency and interoperability and slowing collective progress.

\vspace{1em}
We define a harmonised, tool-agnostic specification that establishes a shared data architecture and scientific approach for variant interpretation in Mendelian disease. The guideline sets minimum requirements for representing, linking and auditing evidence, including sequence and sample provenance, variant normalisation, segregation logic, phenotype alignment, evidence grading, conflict handling and versioned synthesis statements. It emphasises structured, reviewable reasoning rather than fixed classification labels and is designed to complement, not replace, existing standards, tools and workflows.

\vspace{1em}
By formalising a standardised approach to quantifying interpretation, this framework enables distributed groups to solve genomics problems in alignment rather than in parallel isolation. It reduces duplication, supports independent validation, improves automation and ensures that advances in one sector directly strengthen others. The model establishes a shared, exchangeable foundation for interpretation that remains transparent, interoperable and evolvable, strengthening cooperation between national initiatives, healthcare, research and industry.
\footnote{
\noindent * Addresses for correspondence: \href{mailto:Dylan.Lawless@uzh.ch}{Dylan.Lawless@uzh.ch}.\\
% \noindent  \textsuperscript{† }These authors contributed equally and are listed alphabetically.\\
\textbf{Availability:} This data is integrated in 
\url{https://iei-genetics.github.io}.
%available under the MIT licence.
% \url{https://github.com/TheQuantGroup/QauntGroup}.
}
\vfill
\end{abstract}


%TEAM
%TEAM
%Ioannis
%Xenarios
%Chief Data Analytics Officer
%
%CONTACT
%Lorenzo Cerutti
%Bioinformatician
%
%CONTACT
%Arnaud Hungler
%Head of IT
%
%CONTACT
%Katrin Männik
%Head of Genomics Strategy
%
%CONTACT
%Ilya Kolpakov
%Data and Analytics Engineer
%
%CONTACT
%Arkadiy Shevrikuko
%Software Engineer
%
%CONTACT




\tableofcontents



\section{Introduction}
% Set the motivation, problem definition, and need for a national evidence architecture.
Genome sequencing is now routine in research, diagnostics, and commercial genomics, but the evidence supporting variant interpretations is recorded, structured, and justified in widely different ways. Algorithmic scores, proprietary rankings, or pathogenicity labels are often treated as conclusions rather than evidence, while key determinants of validity including sequence provenance, variant identity, inheritance logic, mechanism fit, population context, phenotype alignment, and contradictory observations are inconsistently captured or reported. This fragmentation limits reproducibility, weakens cumulative knowledge, and slows safe integration of AI-driven and cross-sector genomic innovation.

The Swiss Genomics Association is building a national, open infrastructure for shared standards at the intersection of healthcare, research and industry. Our aim is not to replace existing frameworks or tools, but to define the evidential foundation they depend on: transparent, computable, and auditable variant interpretation that preserves biological nuance, remains interoperable across platforms, and retains full reasoning rather than only final labels. By establishing common expectations for evidence traceability, uncertainty, mechanistic reasoning, inheritance verification and phenotype grounding, this guideline enables consistent interpretation that can be exchanged, validated, and built upon by laboratories, companies, hospitals and researchers alike.

This effort strengthens national coordination where common standards are still underdefined, ensuring genomic data remains clinically meaningful, scientifically reusable, and technically compatible with future care models, analytical innovation and AI-supported interpretation.

\section{Purpose and scope of the guideline}
% Define what this guideline covers and what it does not. Focus tightly on variant evidence rules.

\section{Architectural context and national motivation}
% Explain how this work fits into national genomics infrastructure without describing other pillars in detail.

\section{Design principles for evidence-based variant interpretation}
% Lay out clarity, reproducibility, explicit uncertainty, and provenance as core principles.



\section{Data provenance and sample quality requirements}
    % Minimum trust requirements
    % In QV these become flags such as flag_provenance_complete
% Define the minimal provenance fields and QC signals required to ensure trustworthy interpretation inputs.



\section{Evidence rule framework}
% The empty subsections should be filled with content moved from the existing subsections with old titles below.
% Explain the structure of rules and how they generate flags.

We set an important conceptual basis around evidence and counter evidence.
The entire framework is based on reverse reasoning:
For every variant proposed by an upstream tool, the national system tests all available evidence domains for signals that contradict, weaken, or fail to support the hypothesis that this variant is the cause of disease. By default we also need certain agreements on the structure for allowing an interoperable use of results.

\subsection{Structure of evidence rules}
% Old: Rule structure and versioning
% Describe YAML rule definitions, version control, and how rules stay reproducible over time.

\subsection{Versioning and audit trace}
 % Old: Versioning, YAML schemas, reproducibility
 
 \subsection{Optional reference implementation (QV framework)}
        % Old: QV file guideline content
        % Old: Implemented rule set (moved here conceptually)
        % Old: Rules under development (moved here conceptually) 

QV file guideline content

\lstinputlisting[
  style=qvstyle,
 caption={Excerpt from the QV interpretation prompt used with the QV Builder app. Line wrapping is shown for display only. For actual use, refer to the original source file or the corresponding official QV set release.},
  label={lst:qv_variant_interpretation}
]{../qv_variant_interpretaion.txt}

 
Variant interpretation depends on how whole genome data are prepared and analysed. Each step, from sequencing and variant calling to annotation and filtering, defines what can be detected or missed. A qualifying variant (QV) protocol makes these steps explicit by describing the rules that determine variant inclusion and interpretation \cite{2025lawlessApplicationQualifyingVariants}.

A standard QV protocol should specify the sequencing method, genome build, and tools used; the quality thresholds for coverage and genotype confidence; the genomic regions or panels considered; and the annotation or classification systems applied. Defining these parameters in a structured QV file separates logic from execution, allowing reproducible, auditable workflows. Each file has a version and checksum, linking it directly to analysis outputs.  

This standardisation ensures that variant findings are traceable and comparable across studies. It also supports automated pipelines that integrate multiple evidence sources, such as population, functional, and multiomic data, in line with frameworks like the GA4GH Variant Annotation model. The result is consistent, transparent, and quantifiable variant interpretation.

% \subsection{Rules under development}
% List future rules with brief rationale to show planned extension without overreach.

\subsection{Implemented rule set}
% \subsection{QV set preparation} % Present; describes rule structure and builder tool

Qualifying Variant (QV) sets define structured, reproducible variant interpretation rules using a transparent, machine-readable YAML format. Each QV file specifies metadata, filters, and evidence-based criteria in a simple key–value syntax, enabling precise replication of variant selection and interpretation logic across studies. QV sets can be composed interactively using the online \url{https://switzerlandomics.ch/pages/qv_builder/}, which provides an intuitive interface for defining rules, previewing YAML output, and ensuring consistency with established standards. This framework promotes FAIR data principles and harmonised variant interpretation for both research and clinical applications.

\section{Evidence flags}
% Introduce the complete flag set and their role in the framework.

\subsection{Evidence domains}
All evidence domains test whether the observable data contradict the hypothesis that a variant is the cause of disease. Each domain represents a structured attempt at falsification. Population frequency, inheritance, molecular function, phenotype fit, and external assertions are all evaluated using the same principles.


\subsection{Final flag set}
% Present only the authoritative list.
% No examples, no tables, no figures here.
% Present the authoritative list of flags exactly as defined in the rule framework.


\begin{tcolorbox}[
    colback=white!0,
    colframe=black,
    boxrule=1pt,
    arc=1mm,
    outer arc=1mm,
    title=\textbf{\refstepcounter{myboxcounter}\label{box:ga4gh_va_example}Box \themyboxcounter: Flags}
]
\begin{verbatim}
flag_gt_valid
flag_moi_parent_gt_missing_mother
flag_moi_parent_gt_missing_father
flag_moi_parent_gt_missing_any
flag_moi_parent_gt_hom_mother
flag_moi_parent_gt_hom_father
flag_moi_parent_gt_hom_any
flag_moi_parent_conflict_AD
flag_moi_parent_conflict_AR
flag_moi_parent_conflict_XR
flag_moi_parent_conflict_any
flag_popfreq_common
flag_popfreq_rare
flag_popfreq_ultrarare
flag_missing_popfreq
flag_uniprot_hits_any_feature
flag_uniprot_hits_domain_like
flag_uniprot_hits_structural_like
flag_uniprot_hits_ptm_like
flag_uniprot_hits_binding_like
flag_uniprot_hits_variant_like
flag_uniprot_is_lof
flag_uniprot_predicted_nmd
flag_uniprot_truncates_feature
\end{verbatim}
\end{tcolorbox}





\subsection{Interpretation of flag combinations}
% Explain how multiple flags combine into structured evidence states.


\section{Structured representation and interoperability}
% Describe how evidence is encoded for exchange across systems.

\subsection{Alignment with GA4GH Variant Representation and Variant Annotation models}
% Clarify how the framework aligns with GA4GH VRS and VA without duplicating their remit.

% Justifies use of global standards for files (VCF, BAM/CRAM), phenotyping (HPO/ORDO), exchange (Phenopackets, Beacon), and reproducible compute (GA4GH-aligned tools and platforms)
   
%
%
%
%only a handful of papers are essential to reference explicitly if the goal is to anchor your section in established, standards-based genomics rather than the broader prenatal literature.
%
%Here are the **core stand-out references** worth including, grouped by purpose:
%
%**1. Foundational standards and interoperability**
%
%* Jacobsen JOB et al., *Nat Biotechnol*, 2022 — Phenopacket schema (GA4GH).
%* Rambla J et al., *Hum Mutat*, 2022 — Beacon v2 and federated data discovery.
%* Robinson PN et al., *Am J Hum Genet*, 2008 — Human Phenotype Ontology (HPO).
%* Pavan S et al., *PLoS One*, 2017 — Orphanet Rare Disease Ontology (ORDO).
%* McKenna A et al., *Genome Res*, 2010 — GATK framework for standardised variant calling.
%
%**2. Phenotype-driven variant interpretation and standardised automation**
%
%* Smedley D et al., *Nat Protoc*, 2015 — Exomiser: integrated, phenotype-driven prioritisation.
%* Robinson PN et al., *Am J Hum Genet*, 2020 — LIRICAL: interpretable likelihood-ratio framework.
%* Kelly C et al., *Trends Genet*, 2022 — Overview of phenotype-aware prioritisation methods.
%
%**3. Aggregated data and clinical implementation exemplars**
%
%* 100,000 Genomes Project Pilot Investigators, *N Engl J Med*, 2021 — clinical implementation of large-scale rare disease genomics.
%* Wright CF et al., *N Engl J Med*, 2023 — current benchmark for genomic diagnosis in rare paediatric disease.
%
%**4. Prenatal aggregation and ontology extension (for context, not methods)**
%
%* Duyzend MH et al., *Prenat Diagn*, 2024 — synthesis on standards and aggregation in prenatal genomics.
%
%A brief reference list citing only these papers will cover all necessary foundations: standard data models (GA4GH, HPO, ORDO), interoperable exchange (Beacon, Phenopackets), validated variant analysis frameworks (Exomiser, LIRICAL, GATK), and real-world evidence of aggregated, standardised implementation (100kGP, Wright et al., 2023).
%
%Anything beyond these would largely repeat or contextualise rather than expand the standards argument.

% See \url{https://www.ncpi-acc.org} for NIH Cloud Platform Interoperability.

% This section discusses VCF, BAM, HPO, ORDO, Phenopackets, Beacon, cloud pipelines, and Exomiser. It belongs in the interoperability section because it defines external standards the architecture depends on.
Automation, interoperability, and reproducibility in genomics rely on the use of internationally recognised standards rather than isolated or proprietary tools. Validated frameworks enable traceable, comparable, and scalable handling of genomic and phenotypic data across research and clinical contexts \cite{2024duyzendImprovingPrenatalDiagnosis}.

Core standards include the \textbf{Variant Call Format (VCF)}, \textbf{Binary Alignment Map (BAM/CRAM)}, and the \textbf{Phenopacket Schema} from the \textbf{Global Alliance for Genomics and Health (GA4GH)}. The \textbf{Human Phenotype Ontology (HPO)} and \textbf{Orphanet Rare Disease Ontology (ORDO)} support structured phenotyping and disease mapping, while the \textbf{Beacon protocol} enables federated search across distributed datasets without sharing raw data.

Using such standards ensures long-term compatibility, supports automation, and improves accuracy through consistent validation and version control. Tools such as \textit{Exomiser}, \textit{LIRICAL}, and \textit{PhenIX} show how ontology-based approaches enable automated, phenotype-driven variant prioritisation. For cloud analysis, platforms like \textbf{Terra} and pipelines such as \textbf{GATK} provide transparent, reproducible environments aligned with GA4GH and international data-sharing frameworks.





\subsection{GA4GH Variant Annotation model}
% This matches the GA4GH VA explanatory content. It belongs in the interoperability layer, not in the evidence rule layer.  Introduces machine-interpretable evidence models (GA4GH VA), linking variant, condition, and evidence to support quantitative, updateable inference beyond manual ACMG categories

See \url{https://va-spec.ga4gh.org/en/latest/examples/acmg-variant-pathogenicity-statement-with-evidence.html} for example. 

Variant interpretation has traditionally relied on expert review and rule-based systems such as the ACMG/AMP criteria, where evidence is manually classified into discrete levels (e.g. “strong”, “moderate”, “supporting”). While this provides clinical transparency, it limits scalability and does not easily incorporate quantitative or experimental data generated outside the sequencing pipeline.  

Structured annotation frameworks, such as the \textbf{GA4GH Variant Annotation (VA) specification}, provide a way to formalise how evidence supports or refutes pathogenicity, linking statements to their provenance and strength. Rather than a human-readable label alone, each assertion is represented as a computable object that connects a variant, a condition, and all supporting evidence lines. These may include cohort allele frequencies, functional assays, or other study results, each qualified by method, direction, and strength of support. This structure allows integration of diverse evidence types while retaining traceability to original data sources.  

Such a model enables a shift from categorical to quantitative reasoning. A variant’s pathogenicity statement can accumulate weighted evidence from multiple domains: ACMG-derived criteria, \textit{in vitro} functional data (e.g. MAVE), RNA and protein evidence, population studies, or model organism data. Each evidence line can be standardised using controlled vocabularies and shared identifiers, allowing aggregation across studies and automated computation of posterior probabilities.  

Tools such as \textit{Exomiser} and \textit{LIRICAL} illustrate early automation based on ACMG-compatible logic and phenotype-driven scoring. Extending these with the GA4GH VA model allows incorporation of continuous, probabilistic evidence rather than threshold-based categories. This approach transforms variant classification from interpretive judgment into quantifiable inference, reducing subjective variability and supporting automated re-evaluation as new evidence emerges.  

By representing all evidence as structured, machine-interpretable data with defined provenance, the GA4GH framework provides a foundation for fully automatable, transparent, and continuously updatable variant interpretation.


The Variation Representation Specification (VRS) is development by the GA4GH in the Genomic Knowledge Standards (GKS) Work stream;
\url{https://www.ga4gh.org/product/variation-representation/}.

\subsection{Exchange formats and machine readable outputs}
% Define JSON, YAML, or other outputs that ensure interoperability.

\section{Probabilistic interpretation in Pillar 3}
  % Clarifies that current document is foundation for Pillar 3 logic
% Frame this work as the foundation for the probabilistic model used in Pillar 3.

\subsection{Relationship to Pillar 1 and Pillar 2 inputs}
% Clarify dependencies on provenance and normalised analysis variables.

\subsection{Evidence aggregation logic}
% Describe at a high level how evidence states will feed into probabilistic interpretation.

\section{Clinical review checkpoints}
% Define what automated rules cannot do and where expert review must occur.

\subsection{Required manual assessments}
% Provide a concise checklist of mandatory clinical oversight steps.

\subsection{Boundary of automated reasoning}
% State clear limits to prevent over-interpretation of algorithmic evidence.

\section{Reporting and synthesis statements}
% Define the structure and content of final variant reports based on flags and evidence.

\section{Auditability, versioning, and reproducibility}
% Describe logging, provenance, versioning, and how decisions can be reconstructed.

\section{Limitations and scope}
% Explicitly state what falls outside this guideline.

\section{Future extensions}
% Outline expected expansions without committing to specific timelines.




\section{Conclusion}


\section*{Acknowledgements}

\section*{Contributions}
DL designed the analyses and wrote the manuscript.

\section*{Competing interest}
\noindent
The authors declare no competing interest. 

\section*{Ethics statement}
\noindent
This study only used data which was previously published and publicly available, as cited in the manuscript.

\section*{Data availability}
The data used in this manuscript is derived from open sources which are cited in methods. The data generated is available from ...

\section*{Funding}

% \clearpage
\bibliographystyle{unsrtnat}
\bibliography{references}



\section*{Acronyms}
\renewenvironment{description}%
  {\list{}{\labelwidth0pt\itemindent-\leftmargin
    \parsep-1em\itemsep0pt\let\makelabel\descriptionlabel}}
  {\endlist}
\begin{acronym}
\acro{acmg}[ACMG]{American College of Medical Genetics and Genomics}%
\acro{acat}[ACAT]{Aggregated Cauchy Association Test}%
\acro{ad}[AD]{Autosomal Dominant}%
  \acro{af}[AF]{Allele Frequency}
 \acro{aid}[AID]{Autoinflammatory Disorders}
 \acro{anova}[ANOVA]{Analysis of Variance}
 \acro{ar}[AR]{Autosomal Recessive}
 \acro{bmf}[BMF]{Bone Marrow Failure}
 \acro{cd}[CD]{Complement Deficiencies}
 \acro{ci}[CI]{Confidence Interval}
 \acro{cri}[CrI]{Credible Interval}
 \acro{cid}[CID]{Immunodeficiencies affecting Cellular and Humoral Immunity}
 \acro{cid+}[CID+]{Combined Immunodeficiencies with Associated or Syndromic Features}
 \acro{cf}[CF]{Cystic Fibrosis}
 \acro{cftr}[\textit{CFTR}]{Cystic Fibrosis Transmembrane Conductance Regulator}
 \acro{cvid}[CVID]{Common Variable Immunodeficiency}
  \acro{dclre1c}[\textit{DCLRE1C}]{DNA Cross-Link Repair 1C}
 \acro{dbnsfp}[dbNSFP]{database for Non-Synonymous Functional Predictions}
 \acro{ge}[GE]{Genomics England} 
 \acro{gnomad}[gnomAD]{Genome Aggregation Database}
 \acro{grch38}[GRCh38]{Genome Reference Consortium Human Build 38}
\acro{gvcf}[gVCF]{genomic variant call format}
 \acro{hgvs}[HGVS]{Human Genome Variation Society}
\acro{hvnc}[HVNC]{HGVS Variant Nomenclature Committee}
\acro{hugo}[HUGO]{Human Genome Organisation}
 \acro{hpc}[HPC]{High-Performance Computing}
 \acro{hsd}[HSD]{Honestly Significant Difference}
 \acro{hwe}[HWE]{Hardy-Weinberg Equilibrium}
 \acro{iei}[IEI]{Inborn Errors of Immunity}
  \acro{ig}[Ig]{Immunoglobulin}
 \acro{il2rg}[\textit{IL2RG}]{Interleukin 2 Receptor Subunit Gamma}
 \acro{indel}[InDel]{Insertion/Deletion}
 \acro{iuis}[IUIS]{International Union of Immunological Societies}
 \acro{ld}[LD]{Linkage Disequilibrium}
 \acro{loeuf}[LOEUF]{Loss-Of-function Observed/Expected Upper bound Fraction}
 \acro{lof}[LOF]{Loss-of-Function}
 \acro{moi}[MOI]{Mode of Inheritance}
 \acro{nfkb1}[\textit{NFKB1}]{Nuclear Factor Kappa B Subunit 1}
 \acro{omim}[OMIM]{Online Mendelian Inheritance in Man}
 \acro{pad}[PAD]{Predominantly Antibody Deficiencies}
 \acro{pid}[PID]{Primary Immunodeficiency}
 \acro{pird}[PIRD]{Diseases of Immune Dysregulation}
 \acro{ppi}[PPI]{Protein-Protein Interaction}
 \acro{pli}[pLI]{Probability of being Loss-of-function Intolerant}
 \acro{qc}[QC]{Quality Control}
 \acro{rag1}[\textit{RAG1}]{Recombination activating gene 1}
 \acro{scid}[SCID]{Severe Combined Immunodeficiency}
 \acro{snv}[SNV]{Single Nucleotide Variant}
 \acro{skat}[SKAT]{Sequence Kernel Association Test}
 \acro{stringdb}[STRINGdb]{Search Tool for the Retrieval of Interacting Genes/Proteins}
 \acro{tp}[TP]{true positive}
\acro{fp}[FP]{false positive}
\acro{tn}[TN]{true negative}
\acro{fn}[FN]{false negative}
\acro{tnfaip3}[\textit{TNFAIP3}]{Tumor necrosis factor, alpha-induced protein 3}
 \acro{umap}[UMAP]{Uniform Manifold Approximation and Projection}
 \acro{uniprot}[UniProt]{Universal Protein Resource} 
 \acro{vcf}[VCF]{variant call format}
 \acro{vep}[VEP]{Variant Effect Predictor}
 \acro{vre}[VRE]{variant risk estimate}
  \acro{wgs}[WGS]{Whole Genome Sequencing}
 \acro{xl}[XL]{X-Linked}
\end{acronym}

%\\\\\\\\\\\\\\\\\\\\\\\\\\\\
\beginsupplement
\section{Supplemental} \label{Supplemental_text}

Supplemental data are presented under the same headings that correspond to their relevant main text sections. 


\section{Appendix}
% Holds supplementary materials relevant for implementation.

\subsection{Example rule files}
% Provide minimal YAML examples to clarify rule syntax.

\subsection{Example YAML or JSON evidence objects}
% Show how evidence flags appear in machine readable outputs.

\subsection{Worked examples of flagged variants}
% Provide illustrative examples for collaborators and reviewers.




\section{Evidence flags}
% Introduce the complete flag set and their purpose in the architecture.

\subsection{Evidence domains}
\subsubsection{Counter-evidence and conflict handling}
% Specify how benign signals, contradictory data, and mismatches are flagged and not hidden.

\subsubsection{Normalised variant representation and nomenclature}
    % National minimum input requirements
    % In QV these become flags such as flag_hgvs_valid
% Describe HGVS conventions, genome build, normalisation, and how variant identity is stabilised.
% Missing; should specify HGVS, VCF normalisation, reference builds, allele consistency, transcript rules

Accurate variant description depends on consistent use of internationally recognised nomenclature systems. The \ac{hgvs} nomenclature provides the authoritative standard for describing sequence variants at the DNA, RNA, and protein levels. It ensures that each variant is expressed unambiguously and reproducibly across clinical reports, publications, and databases.  

The \ac{hgvs} Nomenclature is maintained by the \ac{hgvs}   \ac{hvnc} under the H \ac{hugo}  and is widely implemented across major genomic resources and clinical interpretation platforms. Current recommendations are detailed in \citet{2024hartHGVSNomenclature2024} and \citet{2016dendunnenHGVSRecommendationsDescription}, which formalise the syntax, reference sequence alignment, and conventions for variant expression.  

Within this guideline, all variants should be reported according to the most recent \ac{hgvs}  Nomenclature release, aligned to an approved reference sequence (RefSeq or Ensembl transcript). Both coding (\texttt{c.}) and protein (\texttt{p.}) level annotations should be provided where possible. Genomic coordinates should follow the \ac{grch38} reference assembly.  

Using standardised nomenclature ensures interoperability between laboratories, software tools, and public databases, reducing ambiguity in variant exchange and supporting precise traceability in both research and clinical reporting.  

\subsubsection{ACMG criteria with counter-factual evidence} % Present but incomplete; should later define explicit additions for contradictory evidence handling

% By aggregating variant sets beyond single-gene analyses, the framework complements established rare variant association tests such as \ac{skat} and \ac{acat} \cite{liu2019acat,li2020dynamic,wu2011rare,lee2012optimal} and aligns with multi-omics integration methods \cite{kong2018nature,howe2021within}. It is compatible with \ac{acmg} guidelines \cite{richards2015standards}, related interpretation frameworks \cite{tavtigian2020fitting,li2017intervar}, and current \ac{qc} standards \cite{pedersen2021effective,anderson2010data}. Standardised systems, including \ac{acmg} Secondary Findings v3.2 \cite{miller2023acmg}, allow integration of these probabilistic results into clinical workflows. Comparison with AlphaMissense scores showed that pathogenicity predictors estimate molecular effect rather than probability of occurrence. Integrating variant-level priors with predictors like AlphaMissense could improve disease relevance by incorporating gene-disease associations  and \ac{moi} for applications in AI/ML.


The \texttt{acmg\_criteria} rule interprets the condensed ACMG criteria column for each variant and flags variants that carry benign evidence. When a variant has passed upstream prioritisation tools such as Exomiser, the ACMG criteria are typically recorded in a single column as a list of applied evidence codes (for example, \texttt{PVS1, PM2, PP3}, or \texttt{BA1}). The downstream rule inspects this condensed string to determine whether it contains any benign evidence codes, recognised by the presence of the letter ``B'' (for example, \texttt{BA1}, \texttt{BS1--BS4}, or \texttt{BP1--BP8}). Variants with such codes are retained but marked for review, similar to those carrying gnomAD quality flags. This ensures that variants with benign evidence are not automatically excluded but instead require explicit assessment or justification in the final clinical interpretation.

Rank based scoring such as that from Tavanian offers benefits but similarly can miss the presence of counter-factual evidence that a variant might be considered benign but remain prioritised by the presence of other pathogenic flags.

\begin{table}[H]
\small
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{4pt}
\centering
\begin{tabularx}{\linewidth}{l l l X}
\hline
\textbf{variant\_id} & \textbf{ACMG\_criteria} & \textbf{outcome} & \textbf{report\_action} \\
\hline
1 & PVS1, PM2, PP3 & pass & include normally \\
2 & PVS1, PM2, BA1 & pass (flagged) & include with note: ``contains benign ACMG evidence (BA1); review interpretation.'' \\
3 & BP4 & pass (flagged) & include with note: ``benign supporting evidence; verify consistency with phenotype.'' \\
4 & PS2, PM5 & pass & include normally \\
\hline
\end{tabularx}
\caption{Example application of the \texttt{acmg\_criteria} rule to patient variants. Variants containing benign ACMG evidence codes are retained but flagged for explicit review in the final report.}
\label{tab:acmg_criteria}
\end{table}



\subsubsection{Population frequency evidence}
% Define frequency thresholds, rarity logic, missingness flags, and how population data enter interpretation.
\subsubsection{Conditional evidence rules and source-dependent quality checks} % Present; covers conditional database flags (gnomAD example)
% This is fine, but the gnomAD conditional rules are partly part of the flag system, not strictly population frequencies.

Reference databases and the case sample may share variant-calling or sequencing biases. Therefore, databases which carry flagged variants should be examined through conditional automation or manual review. 
For instance, GnomAD is a key reference for interpreting variants in single-case analyses.
The \texttt{gnomad\_flags} rule ensures that flagged variants are reviewed rather than excluded. Variants without a flag (\texttt{NA}) pass directly, while those with recognised gnomAD flags pass with review status.

Common flags include \texttt{AS-VQSR} (allele-specific quality recalibration), \texttt{RF} (random forest outlier), \texttt{LC pLoF} (low-confidence loss-of-function), and \texttt{SEGDUP} (segmental duplication). These indicate potential technical or annotation uncertainty rather than confirmed artefacts.
We recommend that variants are retained in reporting but require justification or comment to ensure transparency and traceability.


\begin{table}[H]
\small
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{4pt}
\centering
\begin{tabularx}{\linewidth}{l l l X}
\hline
\textbf{variant\_id} & \textbf{gnomad\_flag} & \textbf{outcome} & \textbf{report\_action} \\
\hline
1 & NA & pass & include normally \\
2 & LC pLoF & pass (flagged) & include with note: ``gnomAD LC pLoF; review interpretation.'' \\
3 & UnknownFlag & fail & hold for manual review \\
\hline
\end{tabularx}
\caption{Example application of the \texttt{gnomad\_flags} rule to patient variants. Entries automatically wrap within the column width for compact layout.}
\label{tab:gnomad_flags}
\end{table}

\subsubsection{Inheritance and segregation evidence}
% Present trio logic, zygosity checks, parental genotype completeness, and mechanistic compatibility.

Version 1 

When pedigree data are available, \ac{wgs} enables direct evaluation of inheritance models for each variant. Genotypes are interpreted across proband and parents using standard representations such as \texttt{REF}, \texttt{HET}, and \texttt{HOM}, or equivalent encodings used in variant data formats (\texttt{0,1,2} in PLINK, \texttt{0/0}, \texttt{0/1}, \texttt{1/1}, or phased forms such as \texttt{0|1} in VCF). From these data, the inheritance pattern for each variant is determined, such as de novo, homozygous, heterozygous, or compound heterozygous, and this information is then evaluated in relation to the known gene–disease relationship.
For example, the observed segregation pattern may provide supporting or contradictory evidence for an\ac{ad}, \ac{ar}, or \ac{xl} disease mechanism.

Where genotype data are incomplete, inheritance may be inferred from clinical features, family history, or segregation information, but such cases are explicitly flagged as uncertain. Scenarios of incomplete penetrance, such as a heterozygous variant inherited from an unaffected parent, are also recorded because they influence the strength of causal interpretation.
 Each inheritance assessment includes both the inferred pattern and the type of supporting evidence, ensuring that interpretative conclusions in the genetic report transparently reflect the available data and its confidence level.

Version 2

Accurate interpretation of inheritance requires integrating two complementary sources of evidence:  
(1) the \textit{\ac{moi}} defined by curated reference datasets that describe known gene–disease mechanisms, and  
(2) the \textit{observed inheritance pattern} derived from family genotype or clinical data.  

The reference \ac{moi} defines the expected transmission mechanism for a gene–disease pair, typically \ac{ad}, \ac{ar}, or \ac{xl}. Structured datasets such as PanelAppRex \cite{lawless_panelapprex_2025} harmonise these annotations across thousands of curated panels. Foundational sources including Genomics England’s PanelApp and PanelApp Australia \cite{martin_panelapp_2019} provide continuously updated expert curation underpinning national infrastructures such as the NHS National Genomic Test Directory and the 100,000 Genomes Project. The \ac{moi} field thus serves as an evidence-based prior — a quantitative expectation of how pathogenic variants in a given gene are likely to segregate.

The observed inheritance pattern, by contrast, is determined from the case data. When trio or family \ac{wgs} is available, inheritance can be assessed directly from genotype encodings (\texttt{REF}, \texttt{HET}, \texttt{HOM}, or \texttt{0/1}, \texttt{1/1}, \texttt{0|1}). This pattern may confirm or contradict the reference \ac{moi}. For example, a de novo heterozygous variant in an \ac{ad} gene supports causality, whereas biallelic variants in an \ac{ar} gene are expected.  

Cases with incomplete genotype data require inference from clinical or segregation information and must be explicitly flagged as uncertain. Incomplete penetrance, mosaicism, or unaffected carriers (e.g. heterozygous variants in \ac{ar} genes) should be documented, as they influence the posterior probability of pathogenicity \cite{lawless_quantifying_2025}.  

To ensure consistency, each variant interpretation should record both the reference \ac{moi} (from curated databases) and the observed inheritance pattern (from patient data). This dual recording enables probabilistic interpretation frameworks, such as Quant \cite{lawless_quantifying_2025}, to integrate population frequencies, genotype configurations, and inheritance priors under Hardy–Weinberg equilibrium. Together, these components quantify diagnostic confidence and prevent misclassification of variants arising from uncertain or incomplete pedigree information.



\subsubsection{Functional and molecular evidence}
% Describe UniProt feature mapping, domain overlap, truncation patterns, and molecular consequence rules.

Functional evidence from UniProt is integrated by detecting positional overlap between variant amino acid coordinates and annotated protein features recorded in UniProt GFF files. Each UniProt entry provides structured annotations describing biochemical, structural, and functional properties of the protein. For each variant, the affected residue position is compared against these annotated intervals, and any intersection is recorded as supporting evidence in the QV interpretation framework. This approach ensures that experimental and curated protein-level information contributes directly to variant interpretation and reporting (\textbf{Figure ~\ref{fig:tnfaip3_evidence_tracks}}).

The annotated features used as evidence sources include catalytic and binding sites, metal and nucleotide binding regions, and other experimentally defined functional motifs. Structural features such as helices, beta strands, and coiled coils provide spatial context for potential conformational disruption. Domain- and family-level annotations, including domains, motifs, and topological regions, capture conserved structural organisation and functional domains. Additional layers include post-translational modification sites, mutagenesis data, and known sequence variants curated in UniProt. Processing and localisation signals (such as signal peptides, transit peptides, and cleavage products) and cautionary sequence annotations (for example, frameshifts or sequence uncertainty) are also recorded.

By systematically linking these feature classes to variant coordinates, the framework records not only where functional or structural evidence exists, but also the type of information present—whether experimental, inferred, or computational. This enables each variant interpretation to transparently reflect the available molecular evidence supporting its classification.

\begin{figure}[ht]
\centering
\includegraphics[width=0.85\textwidth]{functional_evidence_uniprot.pdf}
\caption{
\textbf{Functional evidence tracks from UniProt annotations.}
The example illustrates how protein-level features such as domains, motifs, and catalytic sites provide structured evidence supporting interpretation of coding variants. 
Overlaps between variant positions and curated functional regions indicate potential mechanistic relevance, while the absence of overlap suggests limited or indirect evidence. 
This evidence framework guides the strength of interpretation in clinical reporting, ensuring that well-supported variants are highlighted and uncertain findings are transparently qualified.
}
\label{fig:tnfaip3_evidence_tracks}
\end{figure}



\subsubsection{Phenotype and gene–disease validity evidence}
% Present phenotype fit, MOI priors, gene validity rules, and disease spectrum alignment.


\end{document}
